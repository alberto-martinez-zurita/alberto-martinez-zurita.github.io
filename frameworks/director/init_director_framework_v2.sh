#!/bin/bash

# Nombre del Proyecto (Carpeta Ra√≠z)
PROJECT_NAME="Director_Framework_Project"

echo "üöÄ Iniciando Protocolo de Despliegue: DIRECTOR FRAMEWORK UNIFICADO (v2.0)..."

# 1. CREACI√ìN DE ESTRUCTURA DE DIRECTORIOS
mkdir -p "$PROJECT_NAME/00_Context"
mkdir -p "$PROJECT_NAME/01_Ideation"
mkdir -p "$PROJECT_NAME/02_Requirements"
mkdir -p "$PROJECT_NAME/03_Architecture"
mkdir -p "$PROJECT_NAME/04_Planning"
mkdir -p "$PROJECT_NAME/05_Development/src"
mkdir -p "$PROJECT_NAME/05_Development/tests"
mkdir -p "$PROJECT_NAME/06_Validation"
mkdir -p "$PROJECT_NAME/07_Closure"

echo "‚úÖ Directorios creados."

# 2. GENERACI√ìN DE ARCHIVOS DE CONTEXTO (RAGs y Prompts)

# --- A. ARCHIVOS DE CONTEXTO NUMERADOS Y CLAR ---

# RAG DIRECTOR [1]
cat << 'EOF' > "$PROJECT_NAME/00_Context/RAG_01_Director.md"
[... CONTENIDO DEL RAG_01_Director.md ...]
# M√âTODO DIRECTOR (Resumen Operativo)

Framework de Prompt Engineering Estructurado.

## ACR√ìNIMO
- **D**elimitadores: Usar ###, """, --- para separar secciones.
- **I**nstrucci√≥n: Verbos de acci√≥n claros (Analiza, Genera, Resume).
- **R**ol: Asignar personalidad experta (Arquitecto, QA, PO).
- **E**jemplos: Few-Shot prompting para guiar el formato.
- **C**ontexto: Datos necesarios para reducir alucinaciones.
- **T**est/Iteraci√≥n: Verificar y refinar.
- **O**bjetivo: Prop√≥sito final del output.
- **R**estricciones: L√≠mites (formato, longitud, estilo).

## T√âCNICAS AVANZADAS
1. **Chain-of-Thought (CoT):** "Piensa paso a paso".
2. **Meta-Prompting:** Usar prompts para generar prompts.
3. **RAG:** Inyectar conocimiento externo (Docs t√©cnicos).
4. **Prompt Chaining:** Desglosar tareas complejas en eslabones secuenciales.
EOF

# RAG R√öBRICA √âLITE [8] (Definitiva)
cat << 'EOF' > "$PROJECT_NAME/00_Context/RAG_08_Rubrica_Elite.md"
[... CONTENIDO DEL RAG_08_Rubrica_Elite.md ...]
# MARCO DE REFERENCIA CLEAR: Nivel √âlite (Knowledge Base)

Este marco define los criterios de aceptaci√≥n para el **Nivel 5 (Optimizado)** seg√∫n el modelo CLEAR. Todo c√≥digo y arquitectura debe ser auditado contra estos est√°ndares estrictos.

## PILAR I: MANTENIBILIDAD COGNITIVA
**Objetivo:** Minimizar la carga cognitiva. El c√≥digo debe ser "obvio" para el lector humano en menos de 30 segundos.

**Reglas de Calidad (Nivel 5):**
1.  **Complejidad Cognitiva:**
    * **< 8** obligatoria para c√≥digo cr√≠tico de negocio.
    * **< 15** umbral m√°ximo absoluto permitido para cualquier funci√≥n.
    * *Auditor√≠a IA:* Revisi√≥n cognitiva total obligatoria para cualquier bloque de c√≥digo generado por IA.
2.  **Cobertura y Calidad de Tests:**
    * Cobertura de C√≥digo **> 85%**.
    * **Mutation Testing** obligatorio para garantizar certeza sem√°ntica (evitar falsos positivos de cobertura).
3.  **Estructura Plana (Aplanamiento):**
    * Prohibido anidamiento superior a **2-3 niveles**.
    * Uso obligatorio de **Guard Clauses** (Retornos tempranos) para mantener el "Happy Path" en el nivel de indentaci√≥n 0.
    * Uso de **Dispatch Tables** (Diccionarios de funciones) para reemplazar cadenas largas de `if-elif-else`.
4.  **Tipado Defensivo:** Tipado est√°tico estricto en el 100% de las fronteras del sistema (ej. uso de Pydantic).

## PILAR II: VELOCIDAD DEL CICLO DE VIDA (LIFECYCLE)
**Objetivo:** Flujo continuo de valor sin fricci√≥n operativa (DORA Elite).

**Umbrales de √âxito (Nivel 5):**
1.  **Frecuencia de Despliegue:** **On-Demand** (M√∫ltiples veces al d√≠a). Pipeline Commit-to-Prod completamente automatizado.
2.  **Lead Time for Changes:** **< 1 Hora** desde el commit hasta la ejecuci√≥n en producci√≥n.
3.  **Change Failure Rate:** **< 5%**.
4.  **M√©tricas de Flujo (Flow Framework):**
    * **Flow Efficiency:** **> 40%** (El tiempo de espera/bloqueo es m√≠nimo respecto al tiempo activo).
    * **Flow Load (WIP):** Estrictamente limitado por equipo ("Pull system" perfecto) para evitar deuda cognitiva por cambio de contexto.
5.  **Desacople:** Uso ubicuo de **Feature Flags** para separar el despliegue t√©cnico del lanzamiento funcional.

## PILAR III: ELASTICIDAD Y MODULARIDAD
**Objetivo:** Arquitectura Antifr√°gil y Desacoplada.

**Reglas Arquitect√≥nicas:**
1.  **Inestabilidad ($I$):** Respetar matem√°ticamente el **Principio de Dependencias Estables** ($I$ dependencias < $I$ dependientes).
2.  **Desacoplamiento:**
    * **Inyecci√≥n de Dependencias (DI):** Total y obligatoria. Prohibida la instanciaci√≥n directa ("hardcoded") de dependencias vol√°tiles (DB, APIs) dentro de las clases.
    * **Arquitectura:** Evoluci√≥n hacia modelos **Event-Driven** o Serverless (Coreograf√≠a pura).
3.  **Evaluaci√≥n de Riesgo:** Existencia de an√°lisis **ATAM** (Architecture Tradeoff Analysis Method) documentado para puntos de sensibilidad y tradeoffs.

## PILAR IV: DISPONIBILIDAD Y CONFIABILIDAD (SRE)
**Objetivo:** Auto-healing y Gobernanza de Errores.

**Reglas Operativas:**
1.  **Resiliencia Autom√°tica:**
    * **Circuit Breaker:** Implementado en el 100% de las integraciones s√≠ncronas externas.
    * **Recuperaci√≥n (MTTR):** **< 1 Hora** (Idealmente Auto-healing sin intervenci√≥n humana).
    * **Retries:** Uso obligatorio de Backoff Exponencial con **Jitter** (aleatoriedad).
2.  **Gobernanza:** Gesti√≥n activa de **Presupuestos de Error** (Error Budgets). Si se agotan, se bloquean autom√°ticamente nuevos deploys (*Feature Freeze*).

## PILAR V: RIESGO Y SEGURIDAD (SECURE BY DESIGN)
**Objetivo:** Inmutabilidad, Compliance Continuo y Zero-Trust.

**Reglas de Seguridad:**
1.  **Infraestructura:** **Inmutable**. No se permiten cambios manuales (SSH) en producci√≥n. Drift Detection autom√°tico activado.
2.  **Vulnerabilidades:**
    * **Gesti√≥n:** Modelo **Zero-Trust**.
    * **Parcheo:** Auto-patching o despliegues Blue-Green para actualizaciones de seguridad sin downtime.
3.  **Compliance as Code:**
    * Validaci√≥n autom√°tica de **CIS Benchmarks**.
    * Reglas de admisi√≥n **OPA** (Open Policy Agent) activas en el pipeline (bloqueantes para configuraciones inseguras).

## PILAR VI: EFICIENCIA DE RECURSOS (FINOPS/GREENOPS)
**Objetivo:** Unit Economics y Sostenibilidad Ambiental.

**Reglas de Eficiencia:**
1.  **FinOps (Nivel 5):**
    * **Tagging:** Cobertura del **100%** de recursos para atribuci√≥n de costes.
    * **Medici√≥n:** **Unit Economics** (Coste por Transacci√≥n) calculado y visible. Chargeback din√°mico implementado.
2.  **GreenOps:**
    * **Memoria:** Uso obligatorio de **Generadores (Lazy Evaluation)** en lugar de listas para colecciones grandes de datos.
    * **Carbono:** Scheduling de cargas de trabajo batch configurado para ventanas temporales de baja intensidad de carbono.
EOF

# RAG T√âCNICO [12] (Placeholder)
cat << 'EOF' > "$PROJECT_NAME/00_Context/RAG_12_Tecnico.md"
# EST√ÅNDARES T√âCNICOS DEL PROYECTO

## Stack Tecnol√≥gico
- Lenguaje: [Definir]
- Framework: [Definir]

## Convenciones
- Naming: CamelCase / snake_case

EOF

# RAG MODELO CLEAR (Filosof√≠a - No tiene ID de flujo)
cat << 'EOF' > "$PROJECT_NAME/00_Context/RAG_Modelo_Clear.md"
[... CONTENIDO DEL RAG_Modelo_Clear.md ...]
# ESTUDIO T√âCNICO Y DOCUMENTACI√ìN ESTRAT√âGICA DEL MODELO DE CALIDAD 'CLEAR': VALIDACI√ìN DE KPIs, DEUDA COGNITIVA Y OPTIMIZACI√ìN DE INFRAESTRUCTURA

**Versi√≥n del Documento:** 2.0

**Fecha:** 27 de Noviembre de 2024

**Elaborado por:** Arquitecto de Software Senior & L√≠der de Pr√°cticas QA (ISO 25000)

**Alcance:** An√°lisis Exhaustivo de los 6 Pilares, Validaci√≥n de M√©tricas Cognitivas y Hoja de Ruta para Plataformas Cloud-Native.

* * *

## 1\. Resumen Ejecutivo

En el panorama actual de la ingenier√≠a de software, la velocidad de entrega y la complejidad sist√©mica han alcanzado puntos de inflexi√≥n cr√≠ticos. La adopci√≥n masiva de herramientas de Inteligencia Artificial Generativa (GenAI) para la producci√≥n de c√≥digo, si bien acelera la fase de desarrollo, introduce riesgos latentes de **Deuda Cognitiva** y **Complejidad Accidental** que amenazan la mantenibilidad a largo plazo. Este informe t√©cnico presenta el modelo de calidad **CLEAR**, un marco de trabajo hol√≠stico dise√±ado para alinear las pr√°cticas modernas de DevOps, SRE y Arquitectura Evolutiva con los rigurosos est√°ndares de la norma **ISO/IEC 25010**. ¬†

El modelo CLEAR estructura la calidad en seis pilares estrat√©gicos: **C**ognitive Maintainability (Mantenibilidad Cognitiva), **L**ifecycle Velocity (Velocidad del Ciclo de Vida), **E**lasticity & Modularity (Elasticidad y Modularidad), **A**vailability & Reliability (Disponibilidad y Confiabilidad), **R**isk & Security (Riesgo y Seguridad), y un sexto pilar transversal de **Resource Efficiency** (Eficiencia de Recursos - FinOps/GreenOps).

A trav√©s de un an√°lisis profundo de la literatura t√©cnica y est√°ndares de la industria, este documento valida la insuficiencia de m√©tricas tradicionales como la Complejidad Ciclom√°tica cuando se utilizan de forma aislada, proponiendo la adopci√≥n mandatoria de la **Complejidad Cognitiva** para evaluar la "comprensibilidad" del c√≥digo generado por humanos y m√°quinas. Adem√°s, se presenta una **R√∫brica de Evaluaci√≥n** detallada que permite clasificar la madurez de los equipos y sistemas desde un nivel _Ad-Hoc_ hasta un nivel _Optimizado_, y se detalla una estrategia de mejora para el nivel de **Plataforma/Infraestructura**, integrando pr√°cticas de observabilidad, seguridad como c√≥digo y sostenibilidad. ¬†

* * *

## 2\. Introducci√≥n y Fundamentos Normativos (ISO 25010)

La ingenier√≠a de software moderna ya no puede evaluarse √∫nicamente bajo la premisa de la "correcci√≥n funcional". La evoluci√≥n hacia arquitecturas distribuidas, microservicios y plataformas nativas de la nube ha expandido la superficie de complejidad, haciendo imperativo un enfoque multidimensional de la calidad. Este estudio se fundamenta en la familia de normas **ISO/IEC 25000 (SQuaRE - Systems and Software Quality Requirements and Evaluation)**, espec√≠ficamente en el modelo de calidad del producto definido en la **ISO/IEC 25010**. ¬†

### 2.1 Alineaci√≥n Estrat√©gica del Modelo CLEAR

El modelo CLEAR no es una reinvenci√≥n arbitraria, sino una adaptaci√≥n pragm√°tica de las ocho caracter√≠sticas de calidad de la ISO 25010 a la realidad operativa de los equipos de alto rendimiento. La correspondencia se establece de la siguiente manera:

-   **Maintainability (Mantenibilidad):** Mapeado al pilar **Cognitive Maintainability**. Se enfoca en la modularidad, reusabilidad, analizabilidad y modificabilidad, pero con un √©nfasis renovado en la carga cognitiva humana necesaria para realizar estos cambios. ¬†
    
-   **Performance Efficiency (Eficiencia de Desempe√±o):** Mapeado al pilar **Resource Efficiency**. Trasciende el tiempo de respuesta para incluir la utilizaci√≥n de recursos y, crucialmente, el coste econ√≥mico (FinOps) y el impacto ambiental (GreenOps). ¬†
    
-   **Reliability (Fiabilidad):** Mapeado al pilar **Availability & Reliability**. Se centra en la madurez, disponibilidad, tolerancia a fallos y capacidad de recuperaci√≥n, aline√°ndose con las pr√°cticas de Ingenier√≠a de Fiabilidad del Sitio (SRE). ¬†
    
-   **Security (Seguridad):** Mapeado al pilar **Risk, Security & Compliance**. Abarca confidencialidad, integridad, no repudio y responsabilidad, integrando controles de seguridad en la infraestructura (CIS Benchmarks). ¬†
    
-   **Portability & Compatibility (Portabilidad y Compatibilidad):** Mapeado al pilar **Elasticity & Architectural Modularity**. Eval√∫a la capacidad del sistema para adaptarse a diferentes entornos (nube h√≠brida, contenedores) y coexistir con otros sistemas. ¬†
    
-   **Functional Suitability (Adecuaci√≥n Funcional):** Mapeado al pilar **Lifecycle Velocity**. Se mide no solo por la presencia de funciones, sino por la velocidad y precisi√≥n con la que se entrega valor al usuario final. ¬†
    

* * *

## 3\. Pilar 1: Cognitive Maintainability (Mantenibilidad Cognitiva) y Salud del C√≥digo

Este pilar representa la base fundacional del modelo. Sin un c√≥digo base saludable y comprensible, cualquier intento de agilidad o escalabilidad est√° condenado al fracaso debido a la fricci√≥n t√©cnica.

### 3.1 El Desaf√≠o de la Deuda Cognitiva en la Era de la IA

Tradicionalmente, la "Deuda T√©cnica" se entend√≠a como el costo de retrabajo causado por elegir una soluci√≥n f√°cil y r√°pida en lugar de una mejor aproximaci√≥n a largo plazo. Sin embargo, la emergencia de herramientas de codificaci√≥n asistida por IA ha introducido un concepto m√°s insidioso: la **Deuda Cognitiva**. ¬†

La Deuda Cognitiva se define como el inter√©s acumulado que se debe pagar con **atenci√≥n humana**. Cuando la IA genera c√≥digo, la salida se percibe como un activo casi gratuito, pero conlleva un pasivo oculto: alguien debe gastar energ√≠a mental para consumir, calificar, interpretar, mejorar, analizar y sintetizar ese c√≥digo. A diferencia de la deuda t√©cnica, que puede ser ignorada temporalmente sin detener la operaci√≥n, la deuda cognitiva paraliza la capacidad de razonamiento del desarrollador en el momento presente. Investigaciones recientes sugieren que el uso de IA sin una supervisi√≥n rigurosa puede reducir el pensamiento cr√≠tico y la resoluci√≥n de problemas independiente, acelerando la "podredumbre del c√≥digo" (code rot) y aumentando la duplicaci√≥n hasta en un 8x. ¬†

### 3.2 Estudio T√©cnico de KPIs: Complejidad Ciclom√°tica vs. Cognitiva

Uno de los requisitos cr√≠ticos de este estudio es validar la pertinencia de los KPIs de complejidad. La industria ha confiado durante d√©cadas en la m√©trica de McCabe, pero el an√°lisis de las fuentes revela que su utilidad como medida √∫nica est√° obsoleta.

#### 3.2.1 Complejidad Ciclom√°tica (McCabe)

Introducida por Thomas McCabe en 1976, esta m√©trica cuantifica el n√∫mero de caminos linealmente independientes a trav√©s del c√≥digo fuente. Se calcula esencialmente como el n√∫mero de puntos de decisi√≥n (if, for, while, case) m√°s uno. ¬†

-   **Validaci√≥n del Umbral (10):** El umbral est√°ndar de la industria de **10** por m√©todo se deriva de la recomendaci√≥n original de McCabe para limitar la complejidad de las rutinas durante el desarrollo. Tanto SonarQube como PMD utilizan este valor por defecto. ¬†
    
-   **Justificaci√≥n T√©cnica:** La complejidad ciclom√°tica es un proxy directo de la **Testabilidad**. El n√∫mero ciclom√°tico define el n√∫mero m√≠nimo de pruebas unitarias necesarias para cubrir todos los caminos posibles del c√≥digo. Un m√©todo con complejidad 25 requiere al menos 25 tests unitarios para una cobertura de caminos completa, lo cual es log√≠sticamente costoso y propenso a errores. ¬†
    
-   **Limitaci√≥n Cr√≠tica:** La m√©trica falla al medir la **Comprensibilidad**. Un `switch` plano con 20 casos tiene una complejidad ciclom√°tica de 20 (alta), pero es trivial de entender para un humano. Por el contrario, tres bucles anidados con l√≥gica booleana compleja pueden tener una complejidad de 6, pero ser cognitivamente impenetrables. ¬†
    

#### 3.2.2 Complejidad Cognitiva (Sonar)

Para abordar las deficiencias de McCabe, SonarSource desarroll√≥ la Complejidad Cognitiva. Esta m√©trica se basa en tres reglas b√°sicas: ignorar estructuras que permiten "taquigraf√≠a" legible (como un switch), incrementar la puntuaci√≥n por cada ruptura en el flujo lineal (bucles, condicionales, recursi√≥n), e incrementar la puntuaci√≥n por **anidamiento**. ¬†

-   **Validaci√≥n del Umbral (15):** La industria y las herramientas de an√°lisis est√°tico como SonarQube han estandarizado un umbral de advertencia en **15** y un error cr√≠tico en **25**. ¬†
    
-   **Superioridad Sem√°ntica:** La Complejidad Cognitiva penaliza el anidamiento profundo porque cada nivel de indentaci√≥n a√±ade una "carga" a la memoria de trabajo del desarrollador, quien debe mantener el contexto de las condiciones superiores. Esto la convierte en una medida mucho m√°s precisa de la **Mantenibilidad** y la **Deuda Cognitiva**. ¬†
    

### 3.3 Estrategia de Evaluaci√≥n CLEAR para el Pilar Cognitivo

El modelo CLEAR prescribe el uso dual de estas m√©tricas con prop√≥sitos distintos:

1.  **Complejidad Ciclom√°tica:** Se utilizar√° estrictamente para dimensionar el **esfuerzo de QA**. Si CC > 10, se requiere una justificaci√≥n de cobertura de pruebas excepcional.
    
2.  **Complejidad Cognitiva:** Se utilizar√° como **Quality Gate** para la mantenibilidad. Se establece un l√≠mite duro de 15 para c√≥digo nuevo, forzando la refactorizaci√≥n preventiva. ¬†
    

* * *

## 4\. Pilar 2: Lifecycle Velocity (Velocidad del Ciclo de Vida) y M√©tricas de Flujo

Este pilar eval√∫a la eficiencia de los procesos de ingenier√≠a, desplazando el foco de la mera actividad (l√≠neas de c√≥digo escritas) a la entrega de valor y resultados operativos.

### 4.1 M√©tricas DORA (DevOps Research and Assessment)

Las m√©tricas DORA se han establecido como el est√°ndar _de facto_ para medir el rendimiento de la entrega de software. Se dividen en m√©tricas de velocidad y estabilidad. ¬†

1.  **Deployment Frequency (Frecuencia de Despliegue):** Mide la cadencia de entrega de valor. Los equipos de √©lite despliegan bajo demanda (m√∫ltiples veces al d√≠a), lo que reduce el tama√±o del lote (batch size) y el riesgo asociado a cada cambio. ¬†
    
2.  **Lead Time for Changes (Tiempo de Entrega de Cambios):** El tiempo desde que el c√≥digo se confirma (commit) hasta que se ejecuta en producci√≥n. Un Lead Time bajo (< 1 hora) indica una alta eficiencia en la pipeline de CI/CD y procesos de revisi√≥n √°giles. ¬†
    
3.  **Change Failure Rate (Tasa de Fallos en Cambios):** El porcentaje de despliegues que requieren una correcci√≥n inmediata (hotfix, rollback). Un valor superior al 15% indica deficiencias en las pruebas automatizadas o en la calidad del c√≥digo. ¬†
    
4.  **Time to Restore Service (Tiempo de Restauraci√≥n):** Cu√°nto tiempo toma recuperarse de un fallo en producci√≥n.
    

### 4.2 M√©tricas de Flujo (Flow Framework)

Mientras que DORA mide los resultados del proceso de entrega, las M√©tricas de Flujo (basadas en el Flow Framework del Dr. Mik Kersten) diagnostican la eficiencia interna del flujo de valor, permitiendo identificar _por qu√©_ los resultados de DORA son los que son. ¬†

1.  **Flow Velocity:** Cu√°nto valor se entrega en un periodo dado.
    
2.  **Flow Efficiency:** La relaci√≥n entre el tiempo activo de trabajo y el tiempo total de espera. Una eficiencia baja (com√∫n en organizaciones tradicionales, a menudo < 10%) se√±ala cuellos de botella organizacionales, esperas por aprobaciones o dependencias bloqueantes. ¬†
    
3.  **Flow Load:** La cantidad de trabajo en progreso (WIP). Un Flow Load excesivo correlaciona directamente con una alta Deuda Cognitiva y un aumento en el Lead Time, debido a la penalizaci√≥n por cambio de contexto. ¬†
    
4.  **Flow Time:** El tiempo total desde que una solicitud es aceptada hasta que se entrega.
    

**Integraci√≥n en CLEAR:** El modelo utiliza DORA como el "term√≥metro" de la salud del equipo y las M√©tricas de Flujo como la "resonancia magn√©tica" para diagnosticar problemas sist√©micos. ¬†

* * *

## 5\. Pilar 3: Elasticity & Architectural Modularity (Elasticidad y Modularidad Arquitect√≥nica)

La arquitectura del software determina los l√≠mites de su escalabilidad y mantenibilidad. Este pilar aborda la estructura est√°tica y din√°mica del sistema.

### 5.1 Modularidad y Acoplamiento

La modularidad se eval√∫a mediante la m√©trica de **Acoplamiento (Coupling)** y **Cohesi√≥n**. Un dise√±o modular efectivo busca una alta cohesi√≥n (los elementos dentro de un m√≥dulo pertenecen juntos funcionalmente) y un bajo acoplamiento (dependencias m√≠nimas entre m√≥dulos). ¬†

-   **KPI Clave: Instability (I):** I\=Ca+CeCe‚Äã, donde Ce es el acoplamiento eferente (saliente) y Ca es el aferente (entrante).
    
-   **KPI Clave: Structural Debt Index (SDI):** Un √≠ndice compuesto que captura la deuda arquitect√≥nica oculta que surge de dependencias c√≠clicas o violaciones de capas. ¬†
    

### 5.2 Evaluaci√≥n de Riesgo Arquitect√≥nico (ATAM)

Para cuantificar el riesgo, el modelo CLEAR integra el **Architecture Tradeoff Analysis Method (ATAM)**. Este m√©todo sistem√°tico eval√∫a c√≥mo las decisiones arquitect√≥nicas satisfacen atributos de calidad espec√≠ficos a trav√©s de escenarios de uso, crecimiento y exploraci√≥n. ¬†

-   **Utility Tree:** Se utiliza para priorizar los atributos de calidad (ej. latencia vs. seguridad) y definir escenarios de prueba concretos.
    
-   **Puntos de Sensibilidad y Tradeoffs:** Identificaci√≥n expl√≠cita de componentes donde un cambio leve impacta significativamente en la calidad (puntos de sensibilidad) y decisiones donde la mejora de una cualidad degrada otra (tradeoffs). ¬†
    

### 5.3 Modelos de Madurez Cloud Native

La infraestructura subyacente se eval√∫a utilizando el Modelo de Madurez de la CNCF, progresando desde el Nivel 1 (Build/Construcci√≥n) hasta el Nivel 5 (Adapt/Adaptaci√≥n), donde la orquestaci√≥n y la escalabilidad son din√°micas y autom√°ticas. ¬†

* * *

## 6\. Pilar 4: Availability & Reliability (Disponibilidad y Confiabilidad)

Este pilar adopta los principios de **Site Reliability Engineering (SRE)** para gestionar la estabilidad operativa.

### 6.1 M√©tricas de Fiabilidad: MTTR, MTBF y MTBF

Es crucial distinguir y aplicar correctamente estas m√©tricas : ¬†

-   **MTBF (Mean Time Between Failures):** Mide la confiabilidad intr√≠nseca del sistema. Un MTBF alto indica robustez.
    
-   **MTTR (Mean Time To Repair/Recover):** Mide la resiliencia y la eficacia de la respuesta a incidentes. En entornos modernos distribuidos, se prioriza la reducci√≥n del MTTR sobre la maximizaci√≥n absoluta del MTBF, bajo la premisa de que "el fallo es inevitable". ¬†
    
-   **Error Budgets (Presupuestos de Error):** Definidos a partir de los SLOs (Service Level Objectives). Si un servicio tiene un objetivo de disponibilidad del 99.9%, el 0.1% restante es el presupuesto de error. Si se agota, se detienen los lanzamientos de nuevas funcionalidades para priorizar la estabilidad. ¬†
    

* * *

## 7\. Pilar 5: Risk, Security & Compliance (Riesgo, Seguridad y Cumplimiento)

La seguridad se integra como un atributo de calidad intr√≠nseco, no como una fase posterior.

### 7.1 Seguridad en la Infraestructura (IaC)

La adopci√≥n de **Infrastructure as Code (IaC)** permite auditar la seguridad de la infraestructura antes del despliegue.

-   **CIS Benchmarks:** Las gu√≠as del Center for Internet Security proporcionan configuraciones prescriptivas para asegurar sistemas operativos, nubes y contenedores. El modelo CLEAR exige una adherencia medida porcentualmente a estos benchmarks. ¬†
    
-   **Escaneo de IaC:** Herramientas como Checkov o TFLint deben integrarse en el pipeline para detectar malas configuraciones (ej. buckets S3 p√∫blicos, grupos de seguridad abiertos) en tiempo de compilaci√≥n. ¬†
    

* * *

## 8\. Pilar 6: Resource Efficiency (Eficiencia de Recursos - FinOps/GreenOps)

Este pilar responde a la necesidad econ√≥mica y ecol√≥gica de la computaci√≥n moderna.

### 8.1 FinOps: Eficiencia Econ√≥mica

La eficiencia no es solo t√©cnica, es financiera.

-   **Resource Utilization Rate:** Medici√≥n precisa de la utilizaci√≥n de CPU/Memoria vs. la asignaci√≥n solicitada (Requests/Limits en Kubernetes). Una baja utilizaci√≥n indica desperdicio (waste). ¬†
    
-   **Cost Allocation:** Porcentaje de la factura de la nube que puede atribuirse directamente a un equipo, producto o servicio. La visibilidad impulsa la responsabilidad. ¬†
    

### 8.2 GreenOps: Sostenibilidad del Software

El impacto ambiental del software es ahora una m√©trica de calidad.

-   **Intensidad de Carbono:** Optimizaci√≥n de cargas de trabajo para ejecutarse en regiones o momentos con menor intensidad de carbono en la red el√©ctrica. ¬†
    
-   **C√≥digo Verde:** Refactorizaci√≥n orientada a la eficiencia energ√©tica, reduciendo ciclos de CPU innecesarios y transmisi√≥n de datos. ¬†
    

* * *

## 9\. R√∫brica de Evaluaci√≥n Detallada del Modelo CLEAR

A continuaci√≥n, se presenta la r√∫brica consolidada para evaluar el nivel de madurez de un sistema o equipo. Se definen 5 niveles: **Nivel 1 (Cr√≠tico/Ad-Hoc)**, **Nivel 2 (Pobre/Reactivo)**, **Nivel 3 (Definido/Est√°ndar)**, **Nivel 4 (Gestionado/Cuantitativo)** y **Nivel 5 (Optimizado/CLEAR)**.

### 9.1 Tabla de Evaluaci√≥n: C√≥digo y Mantenibilidad Cognitiva

M√©trica / KPI

Nivel 1: Cr√≠tico

Nivel 2: Pobre

Nivel 3: Definido

Nivel 4: Gestionado

Nivel 5: Optimizado

**Complejidad Cognitiva**

Sin medici√≥n. M√©todos > 50 comunes. Deuda Cognitiva Alta.

Medida pero ignorada. M√©todos frecuentemente > 30.

**Umbral 15** aplicado a c√≥digo nuevo. Refactorizaci√≥n reactiva.

Umbral 10. Calidad del c√≥digo es criterio de aceptaci√≥n.

**Umbral 8.** C√≥digo "Obvio". Tolerancia cero a complejidad injustificada.

**Complejidad Ciclom√°tica (CC)**

Avg CC > 25. Testing imposible.

Avg CC 15-25. Tests fr√°giles.

**Avg CC ‚â§ 15.** M√°x ‚â§ 30. Testing estructurado.

Avg CC ‚â§ 10. M√°x ‚â§ 20. Alta testabilidad.

**Avg CC ‚â§ 5.** L√≥gica lineal y funcional pura.

**Cobertura de C√≥digo**

< 40%. Testing manual predominante.

40-60%. Falsos positivos comunes.

**60-75%.** Integrado en CI.

**80%.** El est√°ndar de oro.

**\> 85% + Mutation Testing.** Certeza sem√°ntica.

**Deuda T√©cnica (SQALE)**

Rating E (>50% ratio). Bancarrota t√©cnica.

Rating D (20-50%). Desarrollo lento.

Rating C (10-20%). Gestionable.

Rating B (5-10%). Pago proactivo.

**Rating A (<5%).** Deuda t√©cnica casi inexistente.

**Revisi√≥n de C√≥digo IA**

IA usada sin control. "Copy-paste" ciego.

Revisi√≥n superficial de c√≥digo IA.

Revisi√≥n humana obligatoria enfocada en l√≥gica.

Pol√≠ticas de uso de IA definidas.

**Auditor√≠a Cognitiva** total de c√≥digo generado por IA.

¬†

### 9.2 Tabla de Evaluaci√≥n: Velocidad y Flujo (Lifecycle & Flow)

M√©trica / KPI

Nivel 1: Cr√≠tico

Nivel 2: Pobre

Nivel 3: Definido

Nivel 4: Gestionado

Nivel 5: Optimizado

**DORA Deployment Freq.**

< Mensual.

Mensual - Semanal.

Semanal - Diario.

**On Demand.** M√∫ltiples/d√≠a.

**Flujo Continuo.** Commit-to-Prod autom√°tico.

**DORA Lead Time**

\> 6 Meses.

1-6 Meses.

1 Semana - 1 Mes.

**< 1 D√≠a.**

**< 1 Hora.** Eficiencia √âlite.

**Flow Efficiency**

Desconocida (< 5%). Esperas masivas.

5-15%. Bloqueos frecuentes.

15-25%. Gesti√≥n de colas b√°sica.

25-40%. Optimizaci√≥n de espera.

**\> 40%.** Flujo de valor sin fricci√≥n.

**Flow Load (WIP)**

Sobrecarga cognitiva severa. Burnout.

WIP alto y no gestionado.

L√≠mites de WIP por equipo.

WIP balanceado con capacidad.

**WIP √ìptimo.** "Pull system" perfecto.

¬†

### 9.3 Tabla de Evaluaci√≥n: Arquitectura e Infraestructura

M√©trica / KPI

Nivel 1: Cr√≠tico

Nivel 2: Pobre

Nivel 3: Definido

Nivel 4: Gestionado

Nivel 5: Optimizado

**Acoplamiento**

Monolito "Big Ball of Mud".

Capas l√≥gicas con dependencias cruzadas.

Modular Monolith / Servicios grandes.

Microservicios / Desacoplado.

**Event-Driven / Serverless.** Coreograf√≠a pura.

**Riesgo Arquitect√≥nico**

Desconocido. Fallos en cascada.

Reactivo tras incidentes.

**ATAM** anual. Riesgos documentados.

Evaluaci√≥n continua de deuda arquitect√≥nica.

**Arquitectura Antifr√°gil.** Mejora con el estr√©s.

**Madurez Cloud (CNCF)**

Nivel 1: Build. Pre-prod solamente.

Nivel 2: Operate. Ops manuales.

Nivel 3: Scale. Procesos documentados.

Nivel 4: Improve. Pol√≠ticas automatizadas.

**Nivel 5: Adapt.** Orquestaci√≥n aut√≥noma.

¬†

### 9.4 Tabla de Evaluaci√≥n: Fiabilidad y Seguridad

M√©trica / KPI

Nivel 1: Cr√≠tico

Nivel 2: Pobre

Nivel 3: Definido

Nivel 4: Gestionado

Nivel 5: Optimizado

**DORA Change Failure**

\> 46%. Inestable.

31-45%. Riesgoso.

16-30%. Aceptable.

**0-15%.** √âlite.

**< 5%.** Calidad intr√≠nseca.

**MTTR (Recuperaci√≥n)**

\> 6 Meses / Indefinido.

1 Semana - 1 Mes.

< 1 D√≠a.

**< 1 Hora.**

**Auto-healing.** Recuperaci√≥n sin intervenci√≥n humana.

**CIS Benchmarks**

No aplicados. Configs por defecto.

Aplicaci√≥n manual espor√°dica.

**\> 80% Cumplimiento.** Auditor√≠a regular.

Drift Detection automatizado.

**Inmutable.** Cumplimiento continuo forzado.

**Gesti√≥n de Vulnerabilidades**

Cr√≠ticas en producci√≥n.

Parcheo > 30 d√≠as.

Parcheo en SLA (7 d√≠as).

Auto-patching / Blue-Green.

**Zero-Trust.** Seguridad por dise√±o.

¬†

### 9.5 Tabla de Evaluaci√≥n: Eficiencia (FinOps/GreenOps)

M√©trica / KPI

Nivel 1: Cr√≠tico

Nivel 2: Pobre

Nivel 3: Definido

Nivel 4: Gestionado

Nivel 5: Optimizado

**Utilizaci√≥n de Recursos**

"Zombies". Desperdicio masivo.

< 15% CPU avg. Oversized.

20-40%. Rightsizing peri√≥dico.

**Auto-scaling** ajustado.

**Spot instances / Serverless.** Eficiencia m√°xima.

**Asignaci√≥n de Costes**

Factura √∫nica opaca.

Etiquetas por unidad de negocio.

**\> 90% etiquetado.** Showback.

Unit Economics (Coste por transacci√≥n).

**Chargeback** din√°mico y predictivo.

¬†

* * *

## 10\. Propuesta de Mejoras para el Nivel Plataforma/Infraestructura

El an√°lisis revela que muchas organizaciones se estancan en el **Nivel 2 (Operate)** del Modelo de Madurez Cloud Native: tienen la base establecida y aplicaciones en producci√≥n, pero dependen de operaciones manuales y carecen de una estrategia unificada de observabilidad y seguridad. Para ascender hacia los niveles **4 (Improve)** y **5 (Adapt)**, se propone la siguiente hoja de ruta t√©cnica detallada. ¬†

### 10.1 Estrategia de Observabilidad Profunda: Service Mesh vs. API Gateway

Existe una confusi√≥n habitual sobre la interoperabilidad y observabilidad en plataformas distribuidas. Para alcanzar el Nivel 4, es cr√≠tico implementar una arquitectura clara de tr√°fico:

-   **API Gateway (Tr√°fico Norte-Sur):** Debe utilizarse exclusivamente para la entrada de tr√°fico desde clientes externos hacia el cl√∫ster. Sus responsabilidades son: autenticaci√≥n de usuario final, rate limiting, monetizaci√≥n y enrutamiento b√°sico. ¬†
    
-   **Service Mesh (Tr√°fico Este-Oeste):** Para la comunicaci√≥n entre microservicios _dentro_ del cl√∫ster (interoperabilidad), se debe implementar un Service Mesh (ej. Istio, Linkerd).
    
    -   **Beneficio:** Proporciona m√©tricas doradas (Latencia, Tr√°fico, Errores, Saturaci√≥n) de forma autom√°tica para _cada_ servicio sin tocar el c√≥digo de la aplicaci√≥n (patr√≥n sidecar). ¬†
        
    -   **Mejora de KPI:** Reduce dr√°sticamente el MTTR (Pilar Reliability) y aumenta la visibilidad de la arquitectura (Pilar Elasticity).
        

### 10.2 Gobernanza y Seguridad como C√≥digo (Policy-as-Code)

Para mitigar los riesgos del Pilar de Seguridad y avanzar hacia la inmutabilidad:

-   **Implementaci√≥n de OPA (Open Policy Agent):** Se debe integrar OPA o herramientas como Kyverno en el cl√∫ster Kubernetes para actuar como un "Admission Controller".
    
-   **Pol√≠ticas a aplicar:**
    
    -   Prohibir contenedores corriendo como `root`.
        
    -   Exigir etiquetas de coste (FinOps) en todos los recursos.
        
    -   Bloquear despliegues que no provengan de registros de contenedores confiables.
        
-   **Impacto:** Esto automatiza el cumplimiento de los **CIS Benchmarks**, moviendo la seguridad a la izquierda (Shift-Left) y garantizando que la infraestructura sea segura por defecto. ¬†
    

### 10.3 Infraestructura Inmutable y GitOps

Para mejorar la **Velocidad del Ciclo de Vida** y la **Fiabilidad**:

-   **Adopci√≥n de GitOps (ArgoCD / Flux):** El estado deseado de la infraestructura y las aplicaciones debe residir en Git. Cualquier cambio en producci√≥n debe ocurrir a trav√©s de un Pull Request.
    
-   **Beneficio:** Elimina la "configuraci√≥n manual" (Configuration Drift) y permite recuperaciones ante desastres casi instant√°neas (re-aplicando el estado desde Git), mejorando el MTTR. ¬†
    

### 10.4 Optimizaci√≥n FinOps y GreenOps

Para abordar el pilar de **Eficiencia de Recursos**:

-   **Automatizaci√≥n de Rightsizing:** Implementar herramientas (como VPA en Kubernetes o Karpenter) que ajusten din√°micamente los recursos de los nodos y pods bas√°ndose en el uso real, no en estimaciones est√°ticas.
    
-   **Scheduling Consciente del Carbono:** Integrar APIs de intensidad de carbono en el planificador de trabajos batch. Configurar las cargas de trabajo no cr√≠ticas (entrenamiento de modelos IA, reportes anal√≠ticos) para ejecutarse en ventanas temporales donde la energ√≠a de la red sea renovable. ¬†
    

* * *

## 11\. Conclusi√≥n y Recomendaciones Finales

El modelo **CLEAR** representa un salto cualitativo respecto a los enfoques de calidad tradicionales. Al integrar la **Mantenibilidad Cognitiva** como primer pilar, reconoce que el cuello de botella fundamental en el desarrollo moderno no es la capacidad de computaci√≥n, sino la **atenci√≥n humana**.

La validaci√≥n de KPIs realizada en este estudio confirma que, si bien la **Complejidad Ciclom√°tica** sigue siendo √∫til para dimensionar el esfuerzo de pruebas (con un umbral de 10), es la **Complejidad Cognitiva** la que debe gobernar la calidad del c√≥digo en la era de la IA, con un umbral estricto de 15 para prevenir la acumulaci√≥n de deuda cognitiva inmanejable.

Para el nivel de **Plataforma/Infraestructura**, la recomendaci√≥n es clara: abandonar las operaciones manuales y adoptar una postura de **Plataforma como Producto**, utilizando Service Mesh para la observabilidad, GitOps para la consistencia y Policy-as-Code para la seguridad. Solo a trav√©s de esta automatizaci√≥n rigurosa se puede alcanzar la velocidad (DORA Elite) y la estabilidad (MTTR < 1h) requeridas para competir en el mercado actual.

El √©xito en la implementaci√≥n del modelo CLEAR no reside solo en la adopci√≥n de herramientas, sino en la disciplina cultural de tratar la **Deuda Cognitiva** y la **Eficiencia de Recursos** con la misma seriedad que los errores funcionales cr√≠ticos.

* * *



EOF

# RAG ERRORES (Base de Conocimiento)
cat << 'EOF' > "$PROJECT_NAME/00_Context/RAG_Errores.md"
# LECCIONES APRENDIDAS (RAG ERRORES)
## Errores Comunes a Evitar
- **ERR-GEN-01:** No validar inputs de usuario (Riesgo de Inyecci√≥n).
- **ERR-GEN-02:** Hardcodear credenciales en el c√≥digo fuente.
- **ERR-GEN-03:** Tests unitarios dependientes del orden de ejecuci√≥n.
EOF

# PRM_00_Bootloader.md (PROMPT DE INICIO - ACTUALIZADO CON NUEVOS IDs)
cat << 'EOF' > "$PROJECT_NAME/00_Context/PRM_00_Bootloader.md"
[... CONTENIDO DEL PRM_00_Bootloader.md ...]
"""
# DELIMITADORES
Esta es una instrucci√≥n de CONFIGURACI√ìN DE SISTEMA (BOOTLOADER).

# ROL
Eres el "DIRECTOR AI", un orquestador experto en Ingenier√≠a de Software determinista.

# CONTEXTO (INPUTS)
Debes cargar en tu memoria operativa los siguientes documentos adjuntos:
1. "M√©todo DIRECTOR" (Tu sistema operativo de prompts).
2. "Framework CLAR" (Tu sistema de leyes y KPIs).
3. "RAG T√©cnico" (Est√°ndares del proyecto).

# INSTRUCCIONES
1. Internaliza la estructura D.I.R.E.C.T.O.R y las t√©cnicas de Meta-Prompting para todas tus futuras generaciones de prompts.
2. Indexa los KPIs de la R√∫brica √âlite. Entiende que si un entregable viola un KPI (ej. Inyecci√≥n de Dependencias), debe ser rechazado.

3. Entiende tu funci√≥n: No eres un chatbot conversacional, eres una CADENA DE MONTAJE. Tu objetivo es transformar inputs numerados (ej. `OUT_02`) en nuevos prompts o entregables.

# RESTRICCIONES
- No generes c√≥digo ni ideas en esta respuesta.
- Confirma solo cuando hayas le√≠do y entendido los 3 documentos de contexto.

# SALIDA ESPERADA
"‚úÖ SISTEMA DIRECTOR ONLINE (v2.0).
- Contexto CLAR: Cargado.
- M√©todo DIRECTOR: Activo.
- Esperando Input Fase 1 (Idea Bruta)."
"""
EOF

echo "‚úÖ Archivos de Contexto (00) generados y numerados."

# --- B. ARCHIVOS DE TRABAJO (TPLs y PRMs) ---
# [Aqu√≠ se crear√≠an todos los TPLs de las Fases 1 a 5 y el PRM de Auditor√≠a y Retrospectiva.
# Se omite el contenido de los TPLs por brevedad, pero se crear√°n los archivos vac√≠os.]

# TPL FASE 1: IDEATION
cat << 'EOF' > "$PROJECT_NAME/01_Ideation/TPL_01_Objective.md"
[... CONTENIDO DEL TPL_01_Objective.md ...]
"""
# DELIMITADORES
Meta-Prompt para generar la instrucci√≥n de definici√≥n de objetivos.

# ROL
Act√∫a como Meta-Director de Producto.

# CONTEXTO
Dispones de la idea bruta del usuario (Input 4.1) y el RAG Director.

# INSTRUCCIONES
Genera un PROMPT DETALLADO para un Agente de Negocio.
El prompt generado debe solicitar:
1. Un archivo "OUT_01_Obj_Pitch.md" que contenga Objetivos SMART y un Elevator Pitch.
2. Debe obligar al agente a analizar la Alineaci√≥n Estrat√©gica (KPI CLAR D501).
3. Definir criterios de √©xito medibles.

# SALIDA ESPERADA
Solo el bloque de c√≥digo Markdown con el prompt resultante.
"""
EOF

cat << 'EOF' > "$PROJECT_NAME/01_Ideation/IN_01_RawIdea.md"
EOF

# TPL FASE 2: REQUISITOS
cat << 'EOF' > "$PROJECT_NAME/02_Requirements/TPL_02_Reqs.md"
[... CONTENIDO DEL TPL_02_Reqs.md ...]
"""
# DELIMITADORES
Meta-Prompt para generar la instrucci√≥n de Requisitos.

# ROL
Meta-Analista Senior.

# CONTEXTO
Tienes los Objetivos (Entregable 6/OUT_01) y el RAG CLAR.

# INSTRUCCIONES
Genera un PROMPT para un Analista Funcional.
El prompt generado debe:
1. Pedir un desglose de Requisitos Funcionales y No Funcionales.
2. INSTRUCCI√ìN CR√çTICA: Consultar expl√≠citamente el "RAG CLAR" para incluir requisitos de Seguridad (KPI-D301).
3. Solicitar formato tabla Markdown.

# SALIDA ESPERADA
Solo el c√≥digo del prompt generado.
"""
EOF

# TPL FASE 3: ARQUITECTURA
cat << 'EOF' > "$PROJECT_NAME/03_Architecture/TPL_03_Arch.md"
[... CONTENIDO DEL TPL_03_Arch.md ...]
"""
# DELIMITADORES
Meta-Prompt para arquitectura de sistemas.

# ROL
Meta-Arquitecto de Software.

# CONTEXTO
Tienes los Requisitos (OUT_02) y el RAG T√©cnico (Stack definido).

# INSTRUCCIONES
Genera un PROMPT para un Arquitecto de Soluciones.
El prompt generado debe exigir:
1. Documento ADR (Architecture Decision Record).
2. Diagramas en sintaxis Mermaid.
3. Verificaci√≥n contra RAG ERRORES para evitar fallos pasados.
4. Cumplimiento de KPI-D201 (Cloud Native) y KPI-D402 (Modularidad).

# SALIDA ESPERADA
Solo el c√≥digo del prompt generado.
"""
EOF

# TPL FASE 4: PLANNING
cat << 'EOF' > "$PROJECT_NAME/04_Planning/TPL_04_Plan.md"
[... CONTENIDO DEL TPL_04_Plan.md ...]
"""
# DELIMITADORES
Plantilla para generar el Plan Maestro.

# ROL
Project Manager T√©cnico (Scrum Master).

# CONTEXTO (INPUTS)
- Requisitos Detallados (OUT_02).
- Definici√≥n de Arquitectura (OUT_03).

# INSTRUCCIONES
Genera un PROMPT que ordene a un Agente Planificador:
1. Desglosar requisitos en Historias de Usuario t√©cnicas.
2. Agrupar tareas por componentes arquitect√≥nicos.
3. Estimar dependencias.
4. Generar el archivo `OUT_04_MasterPlan.md` como checklist.

# CRITERIOS CLAR
- Priorizar por Valor de Negocio (KPI-D501).
- Tareas at√≥micas aptas para TDD.

# SALIDA ESPERADA
Solo el c√≥digo del prompt generado.
"""

EOF

# TPL FASE 5: DEV (TDD)
cat << 'EOF' > "$PROJECT_NAME/05_Development/TPL_05_Task_TDD.md"
[... CONTENIDO DEL TPL_05_Task_TDD.md ...]
"""
# DELIMITADORES
Plantilla para ejecuci√≥n de Tarea de Desarrollo con TDD.

# ROL
Experto en Clean Code y TDD.

# CONTEXTO GLOBAL
- Objetivos (OUT_01).
- Arquitectura (OUT_03).
- RAG CLAR (KPIs C√≥digo: Complejidad < 10, Cobertura > 80%).

# TAREA ACTUAL
Desarrollar feature: "{{DESCRIPCION_TAREA}}"

# INSTRUCCIONES (CHAIN OF THOUGHT)
Realiza la tarea en dos pasos estrictos:

PASO 1: GENERACI√ìN DE TESTS
- Genera tests unitarios que fallen (Red).
- No generes implementaci√≥n a√∫n.

PASO 2: IMPLEMENTACI√ìN
- Genera el c√≥digo m√≠nimo para pasar los tests (Green).
- Refactoriza para cumplir KPI-C201 (Complejidad).

# RESTRICCIONES
- Respetar RAG T√©cnico.
"""

EOF

# PRM AUDITOR FASE 6
cat << 'EOF' > "$PROJECT_NAME/06_Validation/PRM_06_Auditor.md"
[... CONTENIDO DEL PRM_06_Auditor.md ...]
"""
<role>
  Eres el **Auditor T√©cnico Principal (Lead Auditor)** del framework CLEAR, operando en el **Nivel 5 (Optimizado/√âlite)**.
  
  Tu perfil es √∫nico: combinas la precisi√≥n de un compilador con la visi√≥n estrat√©gica de un CTO. Eres experto en **SRE, FinOps, Psicolog√≠a Cognitiva y Seguridad Zero-Trust**.
  
  Tu superpoder es la **Visi√≥n Dual**:
  1. **Nivel Macro (Arquitectura):** Detectas deuda estructural, acoplamiento inestable y fugas de costes (FinOps) en la organizaci√≥n del proyecto.
  2. **Nivel Micro (C√≥digo):** Escaneas la sintaxis l√≠nea por l√≠nea buscando "Deuda Cognitiva", ineficiencias de memoria (GreenOps) y brechas de seguridad.

  Tu tono es **implacable con la calidad pero pedag√≥gico en la soluci√≥n**. No solo marcas el error, explicas el impacto econ√≥mico y cognitivo del mismo.
</role>

<objective>
  Tu misi√≥n es realizar una **Auditor√≠a Est√°tica Forense** de los archivos proporcionados.
  Debes contrastar rigurosamente el c√≥digo contra la **LEY MARCIAL CLEAR (Nivel √âlite)** definida en tu contexto. 
  
  **Tu meta:** Determinar si el proyecto est√° listo para un entorno de alto rendimiento o si requiere una intervenci√≥n inmediata.
</objective>

<context_knowledge_base>
  [LEY MARCIAL: R√öBRICA CLEAR - NIVEL √âLITE]
  
  ## PILAR I: MANTENIBILIDAD COGNITIVA (Lectura < 30s)
  * **Regla Cr√≠tica:** Complejidad Cognitiva estrictamente **< 8** para c√≥digo cr√≠tico y **< 15** m√°ximo absoluto.
  * **Estructura Plana:** M√°ximo **2-3 niveles** de anidamiento. El "Happy Path" debe estar en indentaci√≥n 0.
  * **Control de Flujo:** Uso obligatorio de **Guard Clauses** y **Dispatch Tables** (Diccionarios). Prohibidas las cadenas `if-elif-else`.
  * **Tipado:** Tipado est√°tico defensivo (Pydantic/Typescript) en el 100% de las fronteras.
  * **Tests:** Exigencia de **Mutation Testing** para validar la certeza sem√°ntica (no solo cobertura de l√≠neas).

  ## PILAR II: VELOCIDAD (LIFECYCLE & DORA)
  * **Objetivo:** Lead Time < 1 Hora.
  * **Regla Cr√≠tica:** Desacople total mediante **Feature Flags**.
  * **Flujo:** Estructura que permita compilaci√≥n aislada para maximizar la **Eficiencia de Flujo (>40%)**.

  ## PILAR III: ELASTICIDAD Y MODULARIDAD (ANTIFR√ÅGIL)
  * **Regla Cr√≠tica (DI):** Inyecci√≥n de Dependencias TOTAL. Prohibida la instanciaci√≥n directa (`new Class()`) de recursos vol√°tiles.
  * **Estabilidad:** Respetar el **Principio de Dependencias Estables** ($I_{dependencias} < I_{dependientes}$).
  * **Arquitectura:** Preferencia por patrones Event-Driven o Serverless.

  ## PILAR IV: CONFIABILIDAD (SRE & GOBERNANZA)
  * **Regla Cr√≠tica:** **Circuit Breaker** en el 100% de llamadas externas.
  * **Recuperaci√≥n:** Estrategias de **Auto-healing** para MTTR < 1 hora.
  * **Retries:** Obligatorio uso de **Exponential Backoff + Jitter** (aleatoriedad).
  * **Gobernanza:** Gesti√≥n de **Presupuestos de Error**.

  ## PILAR V: SEGURIDAD (ZERO-TRUST & COMPLIANCE)
  * **Regla Cr√≠tica:** Infraestructura Inmutable y **Drift Detection**.
  * **Compliance:** Validaci√≥n de reglas **OPA** (Open Policy Agent) y **CIS Benchmarks**.
  * **Sanitizaci√≥n:** Modelo Zero-Trust. Validaci√≥n estricta de esquemas de entrada.

  ## PILAR VI: EFICIENCIA (FINOPS & GREENOPS)
  * **FinOps:** Cobertura de **Tags del 100%** para atribuci√≥n de costes (Unit Economics).
  * **GreenOps (Memoria):** Uso obligatorio de **Generadores (Lazy Eval)** en lugar de Listas para colecciones grandes.
  * **GreenOps (Carbono):** Scheduling de cargas batch en ventanas de baja intensidad de carbono.
</context_knowledge_base>

<input_explanation>
  Recibir√°s dos tipos de entrada. Difer√©ncialos y proc√©salos as√≠:
  
  1. **ARCHIVO `project_content.txt`:** Contiene el √°rbol de directorios y contenido concatenado.
     * *Uso Macro:* Evaluar **Pilar III (Arquitectura/DI)**, **Pilar II (Ciclo de Vida/Tests)** y **Pilar VI (FinOps - Tagging global)**. Busca "Code Smells" estructurales como carpetas 'utils' gigantes o falta de archivos de configuraci√≥n de CI/CD.

  2. **ARCHIVOS INDIVIDUALES ADJUNTOS:** C√≥digo fuente cr√≠tico.
     * *Uso Micro:* Evaluar a fondo **Pilar I (Cognitivo)**, **IV (SRE)**, **V (Seguridad)** y **VI (GreenOps - uso de RAM)**. Calcula la complejidad mentalmente l√≠nea por l√≠nea.
</input_explanation>

<instructions>
  1. **Fase de Reconocimiento (Macro):**
     - Lee `project_content.txt`. ¬øLa estructura grita "Arquitectura Limpia" o "Big Ball of Mud"?
     - Verifica la existencia de tests, configuraciones de linter y pipelines de seguridad.

  2. **Fase de Inspecci√≥n (Micro):**
     - Lee los archivos adjuntos.
     - **C√°lculo Mental:** Estima la Complejidad Cognitiva. Si ves > 2 niveles de anidamiento -> **FALLO (Pilar I)**.
     - **Patrones SRE:** Si ves `requests.get` sin `CircuitBreaker` o `Retry` -> **FALLO CR√çTICO (Pilar IV)**.
     - **Eficiencia:** Si ves una lista completa en memoria `[...]` para muchos datos -> **FALLO (Pilar VI GreenOps)**.
     - **Seguridad:** Si ves inputs sin validar -> **FALLO (Pilar V)**.

  3. **Generaci√≥n de Informe:**
     - S√© implacable. Si el c√≥digo es "funcional" pero dif√≠cil de leer, falla la auditor√≠a.
     - En la secci√≥n de refactorizaci√≥n, **reescribe el c√≥digo** aplicando los patrones CLEAR (Guard Clauses, Generadores, DI).
</instructions>

<chain_of_thought>
  1. Escanear√© la estructura global en busca de Inyecci√≥n de Dependencias. ¬øEst√°n las clases acopladas?
  2. Analizar√© los archivos cr√≠ticos. Identificar√© las "Hotspots" de anidamiento y cadenas `if-else`.
  3. Verificar√© la resiliencia: ¬øQu√© pasa si la DB falla aqu√≠? (Busco Circuit Breakers).
  4. Revisar√© la eficiencia: ¬øSe est√°n usando generadores para ahorrar RAM?
  5. Redactar√© la soluci√≥n educativa mostrando el "Coste" de no hacerlo bien.
</chain_of_thought>

<output_format>
  Genera la respuesta en Markdown:

  # üõ°Ô∏è Informe de Auditor√≠a CLEAR (Nivel √âlite)

  **Veredicto Global:** [Aprobado (Nivel 5) / Requiere Cambios (Nivel 3) / Rechazado (Nivel 1)]

  ## 1. An√°lisis Macro (Arquitectura & Gobernanza)
  * **Salud Estructural:** [An√°lisis de carpetas, modularidad y principio de estabilidad]
  * **Compliance (Pilar V):** [¬øSe detectan configs de seguridad/OPA/CIS?]
  * **FinOps (Pilar VI):** [¬øCobertura de Tagging visible?]

  ## 2. Auditor√≠a Micro (Ficheros Cr√≠ticos)

  ### üìÑ Archivo: `[Nombre del fichero]`
  | Pilar CLEAR | Severidad | Hallazgo | Ubicaci√≥n |
  |---|---|---|---|
  | **I. Cognitivo** | ‚ùå FAIL | Complejidad > 15. Anidamiento de 4 niveles. | Func `process_data` |
  | **IV. SRE** | üî¥ CRIT | Llamada externa sin Circuit Breaker ni Jitter. | L45 |
  | **VI. GreenOps** | ‚ö†Ô∏è WARN | Carga ansiosa (List) en lugar de Lazy (Generator). | L88 |
  | **III. Modularidad**| ‚ùå FAIL | Instanciaci√≥n directa de DB (No hay DI). | Constructor |

  ## üí° Refactorizaci√≥n Educativa (Top Priority)
  
  **Hallazgo:** [Describe el error espec√≠fico]
  **Coste Oculto:** [Explica el impacto: "Alto consumo de RAM", "Bloqueo de hilos", "Imposible de testear"]

  ```python
  # ‚ùå C√ìDIGO ACTUAL (Violaci√≥n)
  def procesar(items):
      db = Database() # Violaci√≥n Pilar III (Acoplamiento)
      res = [x for x in items if x.valid] # Violaci√≥n Pilar VI (Memoria)
      if res:
          if db.check(): # Violaci√≥n Pilar I (Anidamiento)
              # ...
  # ‚úÖ C√ìDIGO CLEAR (Optimizado)
  def procesar(items, db: Database): # Pilar III: Inyecci√≥n de Dependencias
      # Pilar I: Guard Clause
      if not items: return
        
      # Pilar VI: Generador (Lazy Eval)
      items_validos = (x for x in items if x.valid)
        
      # ...
</output_format>
"""
EOF

# PRM FASE 7: CIERRE
cat << 'EOF' > "$PROJECT_NAME/07_Closure/PRM_Retrospective.md"
[... CONTENIDO DEL PRM_Retrospective.md ...]
"""
# DELIMITADORES
Prompt de Retrospectiva y Aprendizaje.

# ROL
Auditor de Calidad.

# INSTRUCCIONES
1. Analiza qu√© fall√≥ y qu√© funcion√≥.
2. Genera contenido para actualizar `RAG_Errores.md` con nuevos fallos detectados.
3. Genera contenido para `RAG_Tecnico.md` con nuevos patrones exitosos.
"""

EOF

# PRM FASE 7: CIERRE
cat << 'EOF' > "$PROJECT_NAME/Director_Workflow.mmd"
graph TD
    %% --- INICIO ---
    Start((INICIO)) --> F0[FASE 0 WARM UP]
    
    %% FASE 0
    F0 -->|In: 1 RAG Dir, 2 Prompt Dir| Agente[Agente Instruido]

    %% --- FASE 1: IDEATION ---
    Agente --> F1_Factory[F1 GENERAR PROMPT]
    F1_Factory -->|In: 3 Plantilla, 4.1 Idea, 4.2 Contexto| Prompt5[Prompt 5 Generado]
    
    Prompt5 --> F1_Exec[F1 EJECUTAR]
    F1_Exec -->|In: 5 Prompt, 4.1, 4.2| Ent6_7[Entregables 6 Obj + 7 Pitch]

    %% --- FASE 2: REQUISITOS ---
    Ent6_7 --> Gate1{Validar Coherencia}
    Gate1 -- No --> F1_Factory
    Gate1 -- Si --> F2_Factory[F2 GENERAR PROMPT]

    F2_Factory -->|In: 8 Template+RAG CLAR, 6, 7| Prompt9[Prompt 9 Generado]
    
    Prompt9 --> F2_Exec[F2 EJECUTAR]
    F2_Exec -->|In: 9 Prompt, 6, 7, 8 RAG| Ent10[Entregable 10 Requisitos]

    %% --- FASE 3: ARQUITECTURA ---
    Ent10 --> Gate2{Validar KPI CLAR}
    Gate2 -- No --> F2_Factory
    Gate2 -- Si --> F3_Factory[F3 GENERAR PROMPT]

    F3_Factory -->|In: 11 Template, 10, 6, 12 RAG TEC| Prompt13[Prompt 13 Generado]

    Prompt13 --> F3_Exec[F3 EJECUTAR]
    F3_Exec -->|In: 13 Prompt, 10, 12 RAG TEC, RAG ERR| Ent14[Entregable 14 ADR + Mermaid]

    %% --- FASE 4: PLAN ---
    Ent14 --> Gate3{Validar KPI CLAR}
    Gate3 -- No --> F3_Factory
    Gate3 -- Si --> F4_Exec[F4 PLANIFICAR]

    F4_Exec -->|In: 10 Reqs, 14 Arq| Ent15[Entregable 15 Master Plan]

    %% --- FASE 5: DESARROLLO (TDD) ---
    Ent15 --> F5_Split[F5 DESGLOSE TAREAS]
    F5_Split -->|In: 15 Plan, 14 Arq, 17 Template Dev| PromptsDev[Prompts Tareas N]

    PromptsDev --> LoopTDD((BUCLE TDD))
    
    LoopTDD -->|Paso A: Generar Test| CodeTest[Codigo Test]
    CodeTest -->|Paso B: Generar Codigo| CodeSource[Codigo Fuente]
    
    CodeSource --> CheckTest{Tests OK?}
    CheckTest -- No Max 10 --> LoopTDD
    CheckTest -- Si --> Ent16[Entregable 16 Verificado]

    %% --- FASE 6 & CIERRE ---
    Ent16 --> F6_Valid[F6 VALIDACION SOFT]
    F6_Valid -->|In: 16 Code, 8 RAG CLAR| Report[Reporte Calidad]

    Report --> GateFinal{Aprobado?}
    GateFinal -- No Critico --> F3_Factory
    GateFinal -- No Leve --> LoopTDD
    GateFinal -- Si --> F7_Close[F7 CIERRE Y APRENDIZAJE]

    F7_Close -->|Update| RAGs[Actualizar RAGs 8, 12, ERR]
    RAGs --> Fin((FIN))
EOF

echo "‚úÖ Plantillas de trabajo y prompts generados."
echo "---------------------------------------------------"
echo "üéâ PROYECTO CREADO EXITOSAMENTE. INICIA con: PRM_00_Bootloader.md"
echo "---------------------------------------------------"